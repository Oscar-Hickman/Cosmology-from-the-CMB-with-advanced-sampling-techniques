{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CMB_with_advanced_sampling_techniques.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMR/1zjai0A/R2yKQDB5A8l",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Oscar-Hickman/Cosmology-from-the-CMB-with-advanced-sampling-techniques/blob/main/CMB_with_advanced_sampling_techniques.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ecZTtAkHrb6A",
        "outputId": "2078172d-bb8f-4d68-9b83-5bec3cebe2e2"
      },
      "source": [
        "!pip install -q healpy\r\n",
        "!pip install camb\r\n",
        "!pip install corner"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 15.8MB 317kB/s \n",
            "\u001b[?25hCollecting camb\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/77/18/4221d569ed621da7e82e81aa8a5a76aae2dc0ee6786e7bbbdefd0df1f887/camb-1.3.0.tar.gz (1.6MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6MB 7.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.6/dist-packages (from camb) (1.4.1)\n",
            "Requirement already satisfied: sympy>=1.0 in /usr/local/lib/python3.6/dist-packages (from camb) (1.1.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scipy>=1.0->camb) (1.19.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.6/dist-packages (from sympy>=1.0->camb) (1.1.0)\n",
            "Building wheels for collected packages: camb\n",
            "  Building wheel for camb (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for camb: filename=camb-1.3.0-cp36-none-any.whl size=1045390 sha256=efda0dd6392a7e392208071721bb7c5b26f035c353ab40606c1d0605d8cda26d\n",
            "  Stored in directory: /root/.cache/pip/wheels/54/8a/29/bb0afc5b177f62f73266cd880fc1516d91c555b611bc80a5d5\n",
            "Successfully built camb\n",
            "Installing collected packages: camb\n",
            "Successfully installed camb-1.3.0\n",
            "Collecting corner\n",
            "  Downloading https://files.pythonhosted.org/packages/5a/ff/df5e34996aec8bc342c72714d1384e9af17259e6f60c2a63da2f53ba1631/corner-2.1.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.6/dist-packages (from corner) (0.36.2)\n",
            "Requirement already satisfied: matplotlib>=2.1 in /usr/local/lib/python3.6/dist-packages (from corner) (3.2.2)\n",
            "Requirement already satisfied: setuptools>=40.6.0 in /usr/local/lib/python3.6/dist-packages (from corner) (53.0.0)\n",
            "Collecting setuptools-scm\n",
            "  Downloading https://files.pythonhosted.org/packages/db/6e/2815f7c8561b088ccedc128681e64daac3d6b2e81a9918b007e244dad8b1/setuptools_scm-5.0.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1->corner) (2.4.7)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1->corner) (1.19.5)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1->corner) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1->corner) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1->corner) (0.10.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib>=2.1->corner) (1.15.0)\n",
            "Installing collected packages: setuptools-scm, corner\n",
            "Successfully installed corner-2.1.0 setuptools-scm-5.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3XsuwJurf0s"
      },
      "source": [
        "#Import Packages\r\n",
        "import tensorflow as tf\r\n",
        "import tensorflow_probability as tfp\r\n",
        "#from tensorflow_probability import experimental\r\n",
        "tfd = tfp.distributions\r\n",
        "import numpy as np\r\n",
        "import scipy as sp\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import healpy as hp\r\n",
        "#import pandas as pd\r\n",
        "import camb \r\n",
        "from camb import model, initialpower\r\n",
        "import glob\r\n",
        "import pylab as plty\r\n",
        "from PIL import Image\r\n",
        "from healpy.sphtfunc import Alm\r\n",
        "import time \r\n",
        "import corner\r\n",
        "#import seaborn as sns\r\n",
        "import scipy.stats as st\r\n",
        "from mpl_toolkits.mplot3d import Axes3D"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgHrOXVQrh2j"
      },
      "source": [
        "#load the chains from the file \r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/content/gdrive')\r\n",
        "#Download the 'Main.py file and import it using:'\r\n",
        "#import Main.ipynb or Main.py\r\n",
        "from Main.ipynb import *\r\n",
        "#from google.colab import files\r\n",
        "#from Main import *\r\n",
        "#exec(open(r'Main.ipynb').read())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0XBHbPisW4v"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1p1S0_KLv11C"
      },
      "source": [
        "#Trial with parameters 1\r\n",
        "parameters = [67.74, 0.0486, 0.2589, 0.06, 0.0, 0.066] #cosmological parameters.\r\n",
        "lmax1 = 4 #lmax value wanted from data\r\n",
        "NSIDE1 = 2  #len(cls1)/3   #3*nside = len(cls)\r\n",
        "Noise_std1 = 0.5 #standard deviation of the noise added to each pixel\r\n",
        "NPIX1 = 12*(NSIDE1**2) #Number of Pixels in the map\r\n",
        "n1 = np.linspace(Noise_std1,Noise_std1,NPIX1) #Array of stds for all the pixels\r\n",
        "Ninv1 = []\r\n",
        "for i in range(NPIX1):\r\n",
        "    Ninv1.append(1/(n1[i]**2)) #finds the inverse noise matrix\r\n",
        "cls1 = call_CAMB_map(parameters, lmax1) #power spectrum for the given parameters and lmax.\r\n",
        "plotpwrspctrm(cls1) #plot of the power spectrum.\r\n",
        "map1 = hpcltomap(cls1, NSIDE1, lmax1)  #generates a map from the power spectrum\r\n",
        "map1 = hpmapsmooth(map1, NSIDE1) #applies a gaussian beam smoother to the map\r\n",
        "noisemap1 = noisemapfunc(map1,n1[0])[0] #adds noise to the map\r\n",
        "hnoisealms1 = hpmaptoalm(noisemap1, lmax1) #noisey alms in my  healpys ordering\r\n",
        "noisealms1 = almhotmo(hnoisealms1, lmax1) #noisy alms in my ordering\r\n",
        "noisecl1 = hpmaptocl(noisemap1, NSIDE1, lmax1) #noisy power spectrum\r\n",
        "plotpwrspctrm(noisecl1) #plots the noisy power spectrum"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RpA4jisuwJo2"
      },
      "source": [
        "#Trial with parameters 2\r\n",
        "lmax2 = 5   #lmax value wanted from data\r\n",
        "NSIDE2 = 2   #len(cls1)/3   #3*nside = len(cls)\r\n",
        "Noise_std2 = 0.5 #standard deviation of the noise added to each pixel\r\n",
        "NPIX2 = 12*(NSIDE2**2) #Number of Pixels in the map\r\n",
        "n2 = np.linspace(Noise_std2,Noise_std2,NPIX2) #Array of stds for all the pixels\r\n",
        "Ninv2 = []\r\n",
        "for i in range(NPIX2):\r\n",
        "    Ninv2.append(1/(n2[i]**2)) #finds the inverse noise matrix\r\n",
        "cls2 = call_CAMB_map(parameters, lmax2) #power spectrum for the given parameters and lmax.\r\n",
        "plotpwrspctrm(cls2) #plot of the power spectrum.\r\n",
        "map2 = hpcltomap(cls2, NSIDE2, lmax2)  #generates a map from the power spectrum\r\n",
        "map2 = hpmapsmooth(map2, NSIDE2) #applies a gaussian beam smoother to the map\r\n",
        "noisemap2 = noisemapfunc(map2,n2[0])[0] #adds noise to the map\r\n",
        "hnoisealms2 = hpmaptoalm(noisemap2, lmax2) #noisey alms in my  healpys ordering\r\n",
        "noisealms2 = almhotmo(hnoisealms2, lmax2) #noisy alms in my ordering\r\n",
        "noisecl2 = hpmaptocl(noisemap2, NSIDE2, lmax2) #noisy power spectrum\r\n",
        "plotpwrspctrm(noisecl2) #plots the noisy power spectrum\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbmWels1xuMe"
      },
      "source": [
        "#Trial with parameters 3\r\n",
        "lmax3 = 6  #lmax value wanted from data\r\n",
        "NSIDE3 = 2  #len(cls1)/3   #3*nside = len(cls)\r\n",
        "Noise_std3 = 0.5 #standard deviation of the noise added to each pixel\r\n",
        "NPIX3 = 12*(NSIDE3**2) #Number of Pixels in the map\r\n",
        "n3 = np.linspace(Noise_std3,Noise_std3,NPIX3) #Array of stds for all the pixels\r\n",
        "Ninv3 = []\r\n",
        "for i in range(NPIX3):\r\n",
        "    Ninv3.append(1/(n3[i]**2)) #finds the inverse noise matrix\r\n",
        "cls3 = call_CAMB_map(parameters, lmax3) #power spectrum for the given parameters and lmax.\r\n",
        "plotpwrspctrm(cls3) #plot of the power spectrum.\r\n",
        "map3 = hpcltomap(cls3, NSIDE3, lmax3)  #generates a map from the power spectrum\r\n",
        "map3 = hpmapsmooth(map3, NSIDE3) #applies a gaussian beam smoother to the map\r\n",
        "noisemap3 = noisemapfunc(map3,n3[0])[0] #adds noise to the map\r\n",
        "hnoisealms3 = hpmaptoalm(noisemap3, lmax3) #noisey alms in my  healpys ordering\r\n",
        "noisealms3 = almhotmo(hnoisealms3, lmax3) #noisy alms in my ordering\r\n",
        "noisecl3 = hpmaptocl(noisemap3, NSIDE3, lmax3) #noisy power spectrum\r\n",
        "plotpwrspctrm(noisecl3) #plots the noisy power spectrum\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stLCd2Q4xubD"
      },
      "source": [
        "#Trial with parameters 4\r\n",
        "lmax4 = 11  #lmax value wanted from data\r\n",
        "NSIDE4 = 4  #len(cls1)/3   #3*nside = len(cls)\r\n",
        "Noise_std4 = 0.5 #standard deviation of the noise added to each pixel\r\n",
        "NPIX4 = 12*(NSIDE4**2) #Number of Pixels in the map\r\n",
        "n4 = np.linspace(Noise_std4,Noise_std4,NPIX4) #Array of stds for all the pixels\r\n",
        "Ninv4 = []\r\n",
        "for i in range(NPIX4):\r\n",
        "    Ninv4.append(1/(n4[i]**2)) #finds the inverse noise matrix\r\n",
        "cls4 = call_CAMB_map(parameters, lmax4) #power spectrum for the given parameters and lmax.\r\n",
        "plotpwrspctrm(cls4) #plot of the power spectrum.\r\n",
        "map4 = hpcltomap(cls4, NSIDE4, lmax4)  #generates a map from the power spectrum\r\n",
        "map4 = hpmapsmooth(map4, NSIDE4) #applies a gaussian beam smoother to the map\r\n",
        "noisemap4 = noisemapfunc(map4,n4[0])[0] #adds noise to the map\r\n",
        "hnoisealms4 = hpmaptoalm(noisemap4, lmax4) #noisey alms in my  healpys ordering\r\n",
        "noisealms4 = almhotmo(hnoisealms4, lmax4) #noisy alms in my ordering\r\n",
        "noisecl4 = hpmaptocl(noisemap4, NSIDE4, lmax4) #noisy power spectrum\r\n",
        "plotpwrspctrm(noisecl4) #plots the noisy power spectrum"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3omzukNxxGF"
      },
      "source": [
        "#Trial with parameters 5\r\n",
        "lmax5 = 12  #lmax of the fitted spectrum\r\n",
        "NSIDE5 = 4  #NSIDE of the map\r\n",
        "Noise_std5 = 0.01 #standard deviation of the noise added to each pixel\r\n",
        "NPIX5 = 12*(NSIDE5**2) #Number of Pixels in the map\r\n",
        "n5 = np.linspace(Noise_std5, Noise_std5, NPIX5) #Array of stds for all the pixels\r\n",
        "Ninv5 = []\r\n",
        "for i in range(NPIX5):\r\n",
        "    Ninv5.append(1/(n5[i]**2)) #finds the inverse noise matrix\r\n",
        "cls5 = call_CAMB_map(parameters, lmax5) #power spectrum for the given parameters and lmax.\r\n",
        "plotpwrspctrm(cls5) #plot of the power spectrum.\r\n",
        "map5 = hpcltomap(cls5, NSIDE5, lmax5)  #generates a map from the power spectrum\r\n",
        "map5 = hpmapsmooth(map5, NSIDE5) #applies a gaussian beam smoother to the map\r\n",
        "noisemap5 = noisemapfunc(map5,n5[0])[0] #adds noise to the map\r\n",
        "hnoisealms5 = hpmaptoalm(noisemap5, lmax5) #noisey alms in my  healpys ordering\r\n",
        "noisealms5 = almhotmo(hnoisealms5,lmax5) #noisy alms in my ordering\r\n",
        "noisecl5 = hpmaptocl(noisemap5, NSIDE5, lmax5) #noisy power spectrum\r\n",
        "plotpwrspctrm(noisecl5) #plots the noisy power spectrum\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rT5a0CrgxxBL"
      },
      "source": [
        "#inital values for the optimisation of psi (with the values from parameters5)\r\n",
        "_number = 1\r\n",
        "\r\n",
        "if _number == 1:\r\n",
        "    lmax = lmax1\r\n",
        "    NSIDE = NSIDE1\r\n",
        "    noisemap = noisemap1\r\n",
        "    clinit = noisecl1\r\n",
        "    noisealm = almhotmo(hnoisealms1,lmax1)\r\n",
        "    Ninv = Ninv1\r\n",
        "    orig_map = map1\r\n",
        "    orig_cls = cls1\r\n",
        "if _number == 2:\r\n",
        "    lmax = lmax2\r\n",
        "    NSIDE = NSIDE2\r\n",
        "    noisemap = noisemap2\r\n",
        "    clinit = noisecl2\r\n",
        "    noisealm = almhotmo(hnoisealms2,lmax2)\r\n",
        "    Ninv = Ninv2\r\n",
        "    orig_map = map2\r\n",
        "    orig_cls = cls2\r\n",
        "if _number == 3:\r\n",
        "    lmax = lmax3\r\n",
        "    NSIDE = NSIDE3\r\n",
        "    noisemap = noisemap3\r\n",
        "    clinit = noisecl3\r\n",
        "    noisealm = almhotmo(hnoisealms3,lmax3)\r\n",
        "    Ninv = Ninv3\r\n",
        "    orig_map = map3\r\n",
        "    orig_cls = cls3\r\n",
        "if _number == 4:\r\n",
        "    lmax = lmax4\r\n",
        "    NSIDE = NSIDE4\r\n",
        "    noisemap = noisemap4\r\n",
        "    clinit = noisecl4\r\n",
        "    noisealm = almhotmo(hnoisealms4,lmax4)\r\n",
        "    Ninv = Ninv4\r\n",
        "    orig_map = map4\r\n",
        "    orig_cls = cls4\r\n",
        "if _number == 5:\r\n",
        "    lmax = lmax5\r\n",
        "    NSIDE = NSIDE5\r\n",
        "    noisemap = noisemap5\r\n",
        "    clinit = noisecl5\r\n",
        "    noisealm = almhotmo(hnoisealms5,lmax5)\r\n",
        "    Ninv = Ninv5\r\n",
        "    orig_map = map5\r\n",
        "    orig_cls = cls5\r\n",
        "if _number == 6:\r\n",
        "    lmax = lmax6\r\n",
        "    NSIDE = NSIDE6\r\n",
        "    noisemap = noisemap6\r\n",
        "    clinit = noisecl6\r\n",
        "    noisealm = almhotmo(hnoisealms6,lmax6)\r\n",
        "    Ninv = Ninv6\r\n",
        "    orig_map = map6\r\n",
        "    orig_cls = cls6\r\n",
        "if _number == 7:\r\n",
        "    lmax = lmax7\r\n",
        "    NSIDE = NSIDE7\r\n",
        "    noisemap = noisemap7\r\n",
        "    clinit = noisecl7\r\n",
        "    noisealm = almhotmo(hnoisealms7,lmax7)\r\n",
        "    Ninv = Ninv7\r\n",
        "    orig_map = map7\r\n",
        "    orig_cls = cls7\r\n",
        "if _number == 8:\r\n",
        "    lmax = lmax8\r\n",
        "    NSIDE = NSIDE8\r\n",
        "    noisemap = noisemap8\r\n",
        "    clinit = noisecl8\r\n",
        "    noisealm = almhotmo(hnoisealms8,lmax8)\r\n",
        "    Ninv = Ninv8\r\n",
        "    orig_map = map8\r\n",
        "    orig_cls = cls8\r\n",
        "if _number == 9:\r\n",
        "    lmax = lmax9\r\n",
        "    NSIDE = NSIDE9\r\n",
        "    noisemap = noisemap9\r\n",
        "    clinit = noisecl9\r\n",
        "    noisealm = almhotmo(hnoisealms9,lmax9)\r\n",
        "    Ninv = Ninv9\r\n",
        "    orig_map = map9\r\n",
        "    orig_cls = cls9\r\n",
        "_sph = []\r\n",
        "for i in range(int((NSIDE**2)*12)):\r\n",
        "    _sph.append([])\r\n",
        "    _count = 0\r\n",
        "    for l in range(lmax):\r\n",
        "        for m in range(l+1):\r\n",
        "            _theta, _phi = hp.pix2ang(nside=NSIDE, ipix=i)\r\n",
        "            _sph[i].append(sp.special.sph_harm(m, l, _phi, _theta))\r\n",
        "            if l==0:    \r\n",
        "                _sph[i][_count] = np.complex(np.real(_sph[i][_count]),np.float64(0.0))\r\n",
        "            _count = _count + 1 \r\n",
        "_sph = tf.convert_to_tensor(_sph, dtype = np.complex128)\r\n",
        "noisemap_tf = tf.convert_to_tensor(noisemap, dtype = np.float64)\r\n",
        "realalminit = noisealm.real\r\n",
        "imagalminit = noisealm.imag\r\n",
        "x0 = []\r\n",
        "len_cl = len(clinit)\r\n",
        "len_ralm = len(realalminit)\r\n",
        "len_ialm = len(imagalminit)\r\n",
        "shape = multtensor(lmax,len_ralm) #A tensor for the spherical harmonics in the maptoalm_tf function\r\n",
        "for i in range(len_cl-2):\r\n",
        "    if clinit[i+2] > 0:\r\n",
        "        x0.append(np.log(clinit[i+2]))\r\n",
        "    else:\r\n",
        "        x0.append(0)\r\n",
        "for i in range(len(realalminit)):\r\n",
        "        x0.append(realalminit[i])\r\n",
        "_count = 0\r\n",
        "for l in range(lmax):\r\n",
        "    for m in range(l + 1):\r\n",
        "        if m!= 0 and m != 1:\r\n",
        "            x0.append(imagalminit[_count])\r\n",
        "        _count = _count + 1\r\n",
        "psi(x0,noisemap,lmax, NSIDE, Ninv)\r\n",
        "x0_tf = tf.convert_to_tensor(x0, dtype = np.float64)\r\n",
        "__psi_record = []\r\n",
        "psi_tf(x0_tf)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwnUhJzbx17U"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_AKOSIuzYWr"
      },
      "source": [
        "#Runs eight different chains with lmax = 12, NSIDE = 4\r\n",
        "lmax4 = 4  #lmax of the fitted spectrum\r\n",
        "NSIDE4 = 2  #NSIDE of the map\r\n",
        "Noise_std4 = 0.5 #standard deviation of the noise added to each pixel\r\n",
        "NPIX4 = 12*(NSIDE4**2) #Number of Pixels in the map\r\n",
        "n4 = np.linspace(Noise_std4, Noise_std4, NPIX4) #Array of stds for all the pixels\r\n",
        "Ninv4 = []\r\n",
        "for i in range(NPIX4):\r\n",
        "    Ninv4.append(1/(n4[i]**2)) #finds the inverse noise matrix\r\n",
        "cls4 = call_CAMB_map(parameters, lmax4) #power spectrum for the given parameters and lmax.\r\n",
        "plotpwrspctrm(cls4) #plot of the power spectrum.\r\n",
        "map4 = hpcltomap(cls4, NSIDE4, lmax4)  #generates a map from the power spectrum\r\n",
        "map4 = hpmapsmooth(map4, NSIDE4) #applies a gaussian beam smoother to the map\r\n",
        "noisemap4 = noisemapfunc(map4,n4[0])[0] #adds noise to the map\r\n",
        "hnoisealms4 = hpmaptoalm(noisemap4, lmax4) #noisey alms in my  healpys ordering\r\n",
        "noisealms4 = almhotmo(hnoisealms4,lmax4) #noisy alms in my ordering\r\n",
        "noisecl4 = hpmaptocl(noisemap4, NSIDE4, lmax4) #noisy power spectrum\r\n",
        "plotpwrspctrm(noisecl4) #plots the noisy power spectrum\r\n",
        "lmax = lmax4\r\n",
        "NSIDE = NSIDE4\r\n",
        "noisemap = noisemap4\r\n",
        "clinit = noisecl4\r\n",
        "noisealm = almhotmo(hnoisealms4,lmax4)\r\n",
        "Ninv = Ninv4\r\n",
        "orig_map = map4\r\n",
        "orig_cls = cls4\r\n",
        "_sph = []\r\n",
        "for i in range(int((NSIDE**2)*12)):\r\n",
        "    _sph.append([])\r\n",
        "    _count = 0\r\n",
        "    for l in range(lmax):\r\n",
        "        for m in range(l+1):\r\n",
        "            _theta, _phi = hp.pix2ang(nside=NSIDE, ipix=i)\r\n",
        "            _sph[i].append(sp.special.sph_harm(m, l, _phi, _theta))\r\n",
        "            if l==0:    \r\n",
        "                _sph[i][_count] = np.complex(np.real(_sph[i][_count]),np.float64(0.0))\r\n",
        "            _count = _count + 1 \r\n",
        "_sph = tf.convert_to_tensor(_sph, dtype = np.complex128)\r\n",
        "noisemap_tf = tf.convert_to_tensor(noisemap, dtype = np.float64)\r\n",
        "realalminit = noisealm.real\r\n",
        "imagalminit = noisealm.imag\r\n",
        "x0 = []\r\n",
        "len_cl = len(clinit)\r\n",
        "len_ralm = len(realalminit)\r\n",
        "len_ialm = len(imagalminit)\r\n",
        "shape = multtensor(lmax,len_ralm) #A tensor for the spherical harmonics in the maptoalm_tf function\r\n",
        "for i in range(len_cl-2):\r\n",
        "    if clinit[i+2] > 0:\r\n",
        "        x0.append(np.log(clinit[i+2]))\r\n",
        "    else:\r\n",
        "        x0.append(0)\r\n",
        "for i in range(len(realalminit)):\r\n",
        "        x0.append(realalminit[i])\r\n",
        "_count = 0\r\n",
        "for l in range(lmax):\r\n",
        "    for m in range(l + 1):\r\n",
        "        if m!= 0 and m != 1:\r\n",
        "            x0.append(imagalminit[_count])\r\n",
        "        _count = _count + 1\r\n",
        "psi(x0,noisemap, lmax, NSIDE, Ninv)\r\n",
        "x0_tf = tf.convert_to_tensor(x0, dtype = np.float64)\r\n",
        "__psi_record = []\r\n",
        "psi_tf(x0_tf)\r\n",
        "__psi_record = []\r\n",
        "start1 = time.time()\r\n",
        "nut_kernel = tfp.mcmc.NoUTurnSampler(target_log_prob_fn=psi_tf, step_size=0.01, max_tree_depth=10, max_energy_diff=1000.0, unrolled_leapfrog_steps=2, parallel_iterations=10)\r\n",
        "samples1, kernel_results1 = run_chain_nut(x0_tf) #Runs the chain\r\n",
        "print(\"Acceptance rate:\", kernel_results1.is_accepted.numpy().mean()) \r\n",
        "finish1 = time.time()\r\n",
        "print('Time taken1 =', finish1 - start1)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3heWQJBhzYUq"
      },
      "source": [
        "lmax4 = 12  #lmax of the fitted spectrum\r\n",
        "NSIDE4 = 4  #NSIDE of the map\r\n",
        "Noise_std4 = 1 #standard deviation of the noise added to each pixel\r\n",
        "NPIX4 = 12*(NSIDE4**2) #Number of Pixels in the map\r\n",
        "n4 = np.linspace(Noise_std4, Noise_std4, NPIX4) #Array of stds for all the pixels\r\n",
        "Ninv4 = []\r\n",
        "for i in range(NPIX4):\r\n",
        "    Ninv4.append(1/(n4[i]**2)) #finds the inverse noise matrix\r\n",
        "cls4 = call_CAMB_map(parameters, lmax4) #power spectrum for the given parameters and lmax.\r\n",
        "plotpwrspctrm(cls4) #plot of the power spectrum.\r\n",
        "map4 = hpcltomap(cls4, NSIDE4, lmax4)  #generates a map from the power spectrum\r\n",
        "map4 = hpmapsmooth(map4, NSIDE4) #applies a gaussian beam smoother to the map\r\n",
        "noisemap4 = noisemapfunc(map4,n4[0])[0] #adds noise to the map\r\n",
        "hnoisealms4 = hpmaptoalm(noisemap4, lmax4) #noisey alms in my  healpys ordering\r\n",
        "noisealms4 = almhotmo(hnoisealms4,lmax4) #noisy alms in my ordering\r\n",
        "noisecl4 = hpmaptocl(noisemap4, NSIDE4, lmax4) #noisy power spectrum\r\n",
        "plotpwrspctrm(noisecl4) #plots the noisy power spectrum\r\n",
        "lmax = lmax4\r\n",
        "NSIDE = NSIDE4\r\n",
        "noisemap = noisemap4\r\n",
        "clinit = noisecl4\r\n",
        "noisealm = almhotmo(hnoisealms4,lmax4)\r\n",
        "Ninv = Ninv4\r\n",
        "orig_map = map4\r\n",
        "orig_cls = cls4\r\n",
        "_sph = []\r\n",
        "for i in range(int((NSIDE**2)*12)):\r\n",
        "    _sph.append([])\r\n",
        "    _count = 0\r\n",
        "    for l in range(lmax):\r\n",
        "        for m in range(l+1):\r\n",
        "            _theta, _phi = hp.pix2ang(nside=NSIDE, ipix=i)\r\n",
        "            _sph[i].append(sp.special.sph_harm(m, l, _phi, _theta))\r\n",
        "            if l==0:    \r\n",
        "                _sph[i][_count] = np.complex(np.real(_sph[i][_count]),np.float64(0.0))\r\n",
        "            _count = _count + 1 \r\n",
        "_sph = tf.convert_to_tensor(_sph, dtype = np.complex128)\r\n",
        "noisemap_tf = tf.convert_to_tensor(noisemap, dtype = np.float64)\r\n",
        "realalminit = noisealm.real\r\n",
        "imagalminit = noisealm.imag\r\n",
        "x0 = []\r\n",
        "len_cl = len(clinit)\r\n",
        "len_ralm = len(realalminit)\r\n",
        "len_ialm = len(imagalminit)\r\n",
        "shape = multtensor(lmax,len_ralm) #A tensor for the spherical harmonics in the maptoalm_tf function\r\n",
        "for i in range(len_cl-2):\r\n",
        "    if clinit[i+2] > 0:\r\n",
        "        x0.append(np.log(clinit[i+2]))\r\n",
        "    else:\r\n",
        "        x0.append(0)\r\n",
        "for i in range(len(realalminit)):\r\n",
        "        x0.append(realalminit[i])\r\n",
        "_count = 0\r\n",
        "for l in range(lmax):\r\n",
        "    for m in range(l + 1):\r\n",
        "        if m!= 0 and m != 1:\r\n",
        "            x0.append(imagalminit[_count])\r\n",
        "        _count = _count + 1\r\n",
        "psi(x0,noisemap, lmax, NSIDE, Ninv)\r\n",
        "x0_tf = tf.convert_to_tensor(x0, dtype = np.float64)\r\n",
        "__psi_record = []\r\n",
        "psi_tf(x0_tf)\r\n",
        "__psi_record = []\r\n",
        "start2 = time.time()\r\n",
        "hmc_kernel = tfp.mcmc.HamiltonianMonteCarlo(target_log_prob_fn=psi_tf, step_size=0.1, num_leapfrog_steps=1)\r\n",
        "samples2, kernel_results2 = run_chain_hmc(x0_tf) #Runs the chain\r\n",
        "print(\"Acceptance rate:\", kernel_results2.is_accepted.numpy().mean()) \r\n",
        "finish2 = time.time()\r\n",
        "print('Time taken2 =', finish2 - start2)\r\n",
        "psis2 = __psi_record"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZ-wjpJwzYR2"
      },
      "source": [
        "#Investigate the time taken for one step for the NUTS, as a function of its inputs.\r\n",
        "times = []\r\n",
        "count = 0\r\n",
        "for i in range(5): #i is the step size (in multiples of 0.02*(i)**3).\r\n",
        "    for k in range(5):\r\n",
        "        __psi_record = []\r\n",
        "        starttime = time.time()\r\n",
        "        nut_kernel = tfp.mcmc.NoUTurnSampler(target_log_prob_fn=psi_tf, step_size=0.02*(i**3), max_tree_depth=10, \r\n",
        "                                             max_energy_diff=(1000*k), unrolled_leapfrog_steps=1, parallel_iterations=10)\r\n",
        "        samples1, kernel_results1 = run_chain_nut(x0_tf) #Runs the chain\r\n",
        "        finishtime = time.time()\r\n",
        "        timetaken = finishtime - starttime\r\n",
        "        print('Time taken =', timetaken)\r\n",
        "        times.append(timetaken)\r\n",
        "        print('count =',count)\r\n",
        "        count = count + 1\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbaCxIPCzYPZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Ro57yZ3xws8"
      },
      "source": [
        "#Optimising the parameters of the posterior (the 'psi' funciton), to get the parameters corresponding to its min.\r\n",
        "sp.optimize.fmin(psi, x0, args = (noisemap, lmax, NSIDE, Ninv), xtol = 1e10, ftol=0.25, maxiter = 100000)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJSEUaab0E-y"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkiyegEx0GLA"
      },
      "source": [
        "samples = samples1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "At9fvkjN0E8Q"
      },
      "source": [
        "lncl_samples = tf.slice(samples,[0,0],[len(samples),lmax-2]) #The sampled cls from the adaptive step size HMC\r\n",
        "cl_samples = tf.math.exp(lncl_samples)\r\n",
        "_zer = tf.constant(0, dtype = np.float64)\r\n",
        "mean_cl = [tf.math.reduce_mean(cl_samples[:,i])  for i in range(lmax-2)] #The mean of the sampled cls from the adaptive step size HMC\r\n",
        "std_cl = [tf.math.reduce_std(cl_samples[:,i])  for i in range(lmax-2)] #The standard deviation of the = sampled cls from the adaptive step size HMC\r\n",
        "mean_cl.insert(0,_zer), mean_cl.insert(0,_zer)\r\n",
        "std_cl.insert(0, _zer), std_cl.insert(0,_zer)\r\n",
        "plt.figure()\r\n",
        "plotpwrspctrm(mean_cl) # Plot of the mean sampled cls\r\n",
        "plotpwrspctrm(orig_cls) #Plot of the original cls\r\n",
        "ell = np.arange(lmax)\r\n",
        "plt.errorbar(ell,(ell*(ell+1)*mean_cl),xerr = 0, yerr = (ell*(ell+1)*std_cl))\r\n",
        "plt.grid()\r\n",
        "plt.legend(('final cls','inital cls'))\r\n",
        "plt.show()\r\n",
        "\r\n",
        "plt.figure(figsize = [10,8])\r\n",
        "[plt.hist((cl_samples[:,i].numpy()), bins = 'auto') for i in range(lmax-2)] #Histogram of the sampled cls for each l value.\r\n",
        "plt.legend((r'$\\ell$ = 0','$\\ell$ = 1','$\\ell$ = 2','$\\ell$ = 3','$\\ell$ = 4','$\\ell$ = 5'))\r\n",
        "plt.grid()\r\n",
        "plt.xlabel('Data:')\r\n",
        "plt.ylabel('Number of Instances:')\r\n",
        "plt.title('The sampling incidents of the HMC for each cl:')\r\n",
        "plt.show()\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RT1KuRQi0Ky4"
      },
      "source": [
        "ralm_samples = tf.slice(samples,[0,lmax-2],[len(samples),len_ralm]) #The real alm samples from the adaptive step size HMC\r\n",
        "ialm_samples = tf.slice(samples,[0,(lmax-2 + len_ralm)],[len(samples),len_ralm-(2*lmax - 1)]) #The imaginary alm samples from the adaptive step size HMC\r\n",
        "mean_ralm = [tf.math.reduce_mean(ralm_samples[:,i])  for i in range(len_ralm)] #The mean of all the samples from the real alms\r\n",
        "mean_ialm = [tf.math.reduce_mean(ialm_samples[:,i])  for i in range(len_ralm-(2*lmax - 1))] #The mean of all the samples from the imaginary alms\r\n",
        "std_ralm = [tf.math.reduce_std(ralm_samples[:,i])  for i in range(len_ralm)] #The standard deviation of all the samples from the real alms\r\n",
        "std_ialm = [tf.math.reduce_std(ialm_samples[:,i])  for i in range(len_ralm-(2*lmax - 1))] #The standard deviation of all the samples from the imaginary alms\r\n",
        "mean_alm = splittosingularalm_tf(mean_ralm, mean_ialm) \r\n",
        "hmean_alm = almmotho(mean_alm,lmax)\r\n",
        "mean_map = hpalmtomap(hmean_alm, NSIDE, lmax) #The mean samples from the HMC as a map\r\n",
        "mollviewmap(orig_map) #Plot of the original map\r\n",
        "mollviewmap(mean_map) #Plot of the mean samples from the HMC as a map\r\n",
        "mollviewmap(abs(orig_map - mean_map)) #A plot of the difference between the original and sampled maps.\r\n",
        "print('Original Map =',orig_map)\r\n",
        "print('Estimated Map =',mean_map)\r\n",
        "print('Absolute Difference =', abs(orig_map - mean_map))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPhQ7a5c0OaA"
      },
      "source": [
        "for i in range(lmax-2):\r\n",
        "    plt.figure(figsize = [10,8])\r\n",
        "    plt.hist(cl_samples[:,i].numpy(), 'auto', density = 'True')  #Histogram of the sampled cls for each l value.\r\n",
        "    plt.xlabel('Data:')\r\n",
        "    plt.ylabel('Probability Density:')\r\n",
        "    plt.title('The sampling incidents of the HMC for each cl:')\r\n",
        "    _xmin, _xmax = 0.9**np.min(cl_samples[:,i].numpy()), 1.1*np.max(cl_samples[:,i].numpy())\r\n",
        "    plt.xlim(_xmin, _xmax)\r\n",
        "    kde_xs = np.linspace(_xmin, _xmax, 300)\r\n",
        "    kde = st.gaussian_kde(cl_samples[:,i].numpy())\r\n",
        "    plt.plot(kde_xs, kde.pdf(kde_xs), 'k', '--')\r\n",
        "    plt.axvline(orig_cls[i+2], color='k', linestyle='dashed', linewidth=1)\r\n",
        "    _meancl = np.mean(cl_samples[:,i].numpy())\r\n",
        "    plt.plot(_meancl, kde.pdf(_meancl),'ro', markersize = 10.5)\r\n",
        "    plt.grid()\r\n",
        "    plt.legend(('Best Fit Plot', r'Mean $C_l$','Data Incidences'))\r\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHUiP8OB0TgP"
      },
      "source": [
        "#LnCl trace plots for the fixed step size hmc\r\n",
        "ex = np.arange(len(lncl_samples))\r\n",
        "for i in range(len_cl - 2):\r\n",
        "    plt.figure()\r\n",
        "    plt.plot(ex,lncl_samples[:,i])\r\n",
        "    plt.plot(ex,lncl_samples[:,i],'x')\r\n",
        "    plt.xlabel('Sample Instance:')\r\n",
        "    plt.ylabel('lncl Value:')\r\n",
        "    _lnclmean = np.mean(lncl_samples[:,i])\r\n",
        "    plt.plot(np.array([0, len(lncl_samples)]),np.array([_lnclmean, _lnclmean]), 'k--')\r\n",
        "    plt.grid()\r\n",
        "    #plt.ylim(ymin = 0)\r\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3niPqmWY0WdW"
      },
      "source": [
        "#Cl trace plots for the fixed step size hmc\r\n",
        "ex = np.arange(len(cl_samples))\r\n",
        "for i in range(len_cl - 2):\r\n",
        "    plt.figure()\r\n",
        "    plt.plot(ex,cl_samples[:,i])\r\n",
        "    plt.plot(ex,cl_samples[:,i],'x')\r\n",
        "    plt.xlabel('Sample Instance:')\r\n",
        "    plt.ylabel('cl Value:')\r\n",
        "    _clmean = np.mean(cl_samples[:,i])\r\n",
        "    plt.plot(np.array([0, len(cl_samples)]),np.array([_clmean, _clmean]), 'k--')\r\n",
        "\r\n",
        "    plt.grid()\r\n",
        "    #plt.ylim(ymin = 0)\r\n",
        "    plt.show()\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fw_KSCZ2zs83"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QzS587WNzs1e"
      },
      "source": [
        "#save the chains to a file called 'test.txti' in case of crashes\r\n",
        "a_file = open('test.txt1', 'w')\r\n",
        "stuff = np.stack((samples1, samples2, samples3, samples4, samples5, samples6, samples7,\r\n",
        "          samples8), axis = 0)\r\n",
        "for row in stuff:\r\n",
        "    np.savetxt(a_file, row)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z73XZlMnztnt"
      },
      "source": [
        "#load the chains from the file \r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/content/gdrive')\r\n",
        "allsamples = np.loadtxt(r'/content/gdrive/My Drive/test.txt').reshape(8,1000, 143)\r\n",
        "samples1, samples2 = tf.constant(allsamples[0]), tf.constant(allsamples[1])\r\n",
        "samples3, samples4 = tf.constant(allsamples[2]), tf.constant(allsamples[3])\r\n",
        "samples5, samples6 = tf.constant(allsamples[4]), tf.constant(allsamples[5])\r\n",
        "samples7, samples8 = tf.constant(allsamples[6]), tf.constant(allsamples[7])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YtXsiV4oztlh"
      },
      "source": [
        "#take the final 200 samples for each of the chains\r\n",
        "#samples1 = samples1[500:]\r\n",
        "samples2 = samples2[:200]\r\n",
        "#samples3 = samples3[500:]\r\n",
        "#samples4 = samples4[500:]\r\n",
        "samples5 = samples5[:200]\r\n",
        "samples6 = samples6[:200]\r\n",
        "#samples7 = samples7[500:]\r\n",
        "samples8 = samples8[:200]\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7-PYfNKzti5"
      },
      "source": [
        "'''\r\n",
        "lncl_samples1 = tf.slice(samples1,[0,0],[len(samples1),lmax-2]) #The sampled cls from the adaptive step size HMC\r\n",
        "cl_samples1 = tf.math.exp(lncl_samples1)\r\n",
        "_zer1 = tf.constant(0, dtype = np.float64)\r\n",
        "mean_cl1 = [tf.math.reduce_mean(cl_samples1[:,i])  for i in range(lmax-2)] #The mean of the sampled cls from the adaptive step size HMC\r\n",
        "std_cl1 = [tf.math.reduce_std(cl_samples1[:,i])  for i in range(lmax-2)] #The standard deviation of the = sampled cls from the adaptive step size HMC\r\n",
        "mean_cl1.insert(0,_zer1), mean_cl1.insert(0,_zer1)\r\n",
        "std_cl1.insert(0, _zer1), std_cl1.insert(0,_zer1)\r\n",
        "plt.figure()\r\n",
        "plotpwrspctrm(mean_cl1) # Plot of the mean sampled cls\r\n",
        "plotpwrspctrm(orig_cls) #Plot of the original cls\r\n",
        "ell = np.arange(lmax)\r\n",
        "plt.errorbar(ell,(ell*(ell+1)*mean_cl1),xerr = 0, yerr = (ell*(ell+1)*std_cl1))\r\n",
        "plt.grid()\r\n",
        "plt.legend(('final cls','inital cls'))\r\n",
        "plt.show()\r\n",
        "plt.figure(figsize = [10,8])\r\n",
        "[plt.hist((cl_samples1[:,i].numpy()), bins = 'auto') for i in range(lmax-2)] #Histogram of the sampled cls for each l value.\r\n",
        "plt.legend((r'$\\ell$ = 0','$\\ell$ = 1','$\\ell$ = 2','$\\ell$ = 3','$\\ell$ = 4','$\\ell$ = 5'))\r\n",
        "plt.grid()\r\n",
        "plt.xlabel('Data:')\r\n",
        "plt.ylabel('Number of Instances:')\r\n",
        "plt.title('The sampling incidents of the HMC for each cl:')\r\n",
        "plt.show()\r\n",
        "'''\r\n",
        "\r\n",
        "lncl_samples2 = tf.slice(samples2,[0,0],[len(samples2),lmax-2]) #The sampled cls from the adaptive step size HMC\r\n",
        "cl_samples2 = tf.math.exp(lncl_samples2)\r\n",
        "_zer2 = tf.constant(0, dtype = np.float64)\r\n",
        "mean_cl2 = [tf.math.reduce_mean(cl_samples2[:,i])  for i in range(lmax-2)] #The mean of the sampled cls from the adaptive step size HMC\r\n",
        "std_cl2 = [tf.math.reduce_std(cl_samples2[:,i])  for i in range(lmax-2)] #The standard deviation of the = sampled cls from the adaptive step size HMC\r\n",
        "mean_cl2.insert(0,_zer2), mean_cl2.insert(0,_zer2)\r\n",
        "std_cl2.insert(0, _zer2), std_cl2.insert(0,_zer2)\r\n",
        "plt.figure()\r\n",
        "plotpwrspctrm(mean_cl2) # Plot of the mean sampled cls\r\n",
        "plotpwrspctrm(orig_cls) #Plot of the original cls\r\n",
        "plotpwrspctrm(clinit)\r\n",
        "ell = np.arange(lmax)\r\n",
        "plt.errorbar(ell,(ell*(ell+1)*mean_cl2),xerr = 0, yerr = (ell*(ell+1)*std_cl2))\r\n",
        "plt.grid()\r\n",
        "plt.legend(('final cls','inital cls'))\r\n",
        "plt.show()\r\n",
        "plt.figure(figsize = [10,8])\r\n",
        "[plt.hist((cl_samples2[:,i].numpy()), bins = 'auto') for i in range(lmax-2)] #Histogram of the sampled cls for each l value.\r\n",
        "plt.legend((r'$\\ell$ = 0','$\\ell$ = 1','$\\ell$ = 2','$\\ell$ = 3','$\\ell$ = 4','$\\ell$ = 5'))\r\n",
        "plt.grid()\r\n",
        "plt.xlabel('Data:')\r\n",
        "plt.ylabel('Number of Instances:')\r\n",
        "plt.title('The sampling incidents of the HMC for each cl:')\r\n",
        "plt.show()\r\n",
        "\r\n",
        "'''\r\n",
        "lncl_samples3 = tf.slice(samples3,[0,0],[len(samples3),lmax-2]) #The sampled cls from the adaptive step size HMC\r\n",
        "cl_samples3 = tf.math.exp(lncl_samples3)\r\n",
        "_zer3 = tf.constant(0, dtype = np.float64)\r\n",
        "mean_cl3 = [tf.math.reduce_mean(cl_samples3[:,i])  for i in range(lmax-2)] #The mean of the sampled cls from the adaptive step size HMC\r\n",
        "std_cl3 = [tf.math.reduce_std(cl_samples3[:,i])  for i in range(lmax-2)] #The standard deviation of the = sampled cls from the adaptive step size HMC\r\n",
        "mean_cl3.insert(0,_zer3), mean_cl3.insert(0,_zer3)\r\n",
        "std_cl3.insert(0, _zer3), std_cl3.insert(0,_zer3)\r\n",
        "#plt.figure()\r\n",
        "#plotpwrspctrm(mean_cl3) # Plot of the mean sampled cls\r\n",
        "#plotpwrspctrm(orig_cls) #Plot of the original cls\r\n",
        "ell = np.arange(lmax)\r\n",
        "#plt.errorbar(ell,(ell*(ell+1)*mean_cl3),xerr = 0, yerr = (ell*(ell+1)*std_cl3))\r\n",
        "plt.grid()\r\n",
        "plt.legend(('final cls','inital cls'))\r\n",
        "#plt.show()\r\n",
        "#plt.figure(figsize = [10,8])\r\n",
        "#[plt.hist((cl_samples3[:,i].numpy()), bins = 'auto') for i in range(lmax-2)] #Histogram of the sampled cls for each l value.\r\n",
        "plt.legend((r'$\\ell$ = 0','$\\ell$ = 1','$\\ell$ = 2','$\\ell$ = 3','$\\ell$ = 4','$\\ell$ = 5'))\r\n",
        "plt.grid()\r\n",
        "plt.xlabel('Data:')\r\n",
        "plt.ylabel('Number of Instances:')\r\n",
        "plt.title('The sampling incidents of the HMC for each cl:')\r\n",
        "plt.show()\r\n",
        "'''\r\n",
        "'''\r\n",
        "lncl_samples4 = tf.slice(samples4,[0,0],[len(samples4),lmax-2]) #The sampled cls from the adaptive step size HMC\r\n",
        "cl_samples4 = tf.math.exp(lncl_samples4)\r\n",
        "_zer4 = tf.constant(0, dtype = np.float64)\r\n",
        "mean_cl4 = [tf.math.reduce_mean(cl_samples3[:,i])  for i in range(lmax-2)] #The mean of the sampled cls from the adaptive step size HMC\r\n",
        "std_cl4 = [tf.math.reduce_std(cl_samples3[:,i])  for i in range(lmax-2)] #The standard deviation of the = sampled cls from the adaptive step size HMC\r\n",
        "mean_cl4.insert(0,_zer4), mean_cl4.insert(0,_zer4)\r\n",
        "std_cl4.insert(0, _zer4), std_cl4.insert(0,_zer4)\r\n",
        "#plt.figure()\r\n",
        "#plotpwrspctrm(mean_cl4) # Plot of the mean sampled cls\r\n",
        "#plotpwrspctrm(orig_cls) #Plot of the original cls\r\n",
        "ell = np.arange(lmax)\r\n",
        "#plt.errorbar(ell,(ell*(ell+1)*mean_cl4),xerr = 0, yerr = (ell*(ell+1)*std_cl4))\r\n",
        "plt.grid()\r\n",
        "plt.legend(('final cls','inital cls'))\r\n",
        "#plt.show()\r\n",
        "#plt.figure(figsize = [10,8])\r\n",
        "#[plt.hist((cl_samples4[:,i].numpy()), bins = 'auto') for i in range(lmax-2)] #Histogram of the sampled cls for each l value.\r\n",
        "plt.legend((r'$\\ell$ = 0','$\\ell$ = 1','$\\ell$ = 2','$\\ell$ = 3','$\\ell$ = 4','$\\ell$ = 5'))\r\n",
        "plt.grid()\r\n",
        "plt.xlabel('Data:')\r\n",
        "plt.ylabel('Number of Instances:')\r\n",
        "plt.title('The sampling incidents of the HMC for each cl:')\r\n",
        "plt.show()\r\n",
        "'''\r\n",
        "'''\r\n",
        "lncl_samples5 = tf.slice(samples5,[0,0],[len(samples5),lmax-2]) #The sampled cls from the adaptive step size HMC\r\n",
        "cl_samples5 = tf.math.exp(lncl_samples5)\r\n",
        "_zer5 = tf.constant(0, dtype = np.float64)\r\n",
        "mean_cl5 = [tf.math.reduce_mean(cl_samples5[:,i])  for i in range(lmax-2)] #The mean of the sampled cls from the adaptive step size HMC\r\n",
        "std_cl5 = [tf.math.reduce_std(cl_samples5[:,i])  for i in range(lmax-2)] #The standard deviation of the = sampled cls from the adaptive step size HMC\r\n",
        "mean_cl5.insert(0,_zer5), mean_cl5.insert(0,_zer5)\r\n",
        "std_cl5.insert(0, _zer5), std_cl5.insert(0,_zer5)\r\n",
        "#plt.figure()\r\n",
        "#plotpwrspctrm(mean_cl5) # Plot of the mean sampled cls\r\n",
        "#plotpwrspctrm(orig_cls) #Plot of the original cls\r\n",
        "ell = np.arange(lmax)\r\n",
        "#plt.errorbar(ell,(ell*(ell+1)*mean_cl5),xerr = 0, yerr = (ell*(ell+1)*std_cl5))\r\n",
        "plt.grid()\r\n",
        "plt.legend(('final cls','inital cls'))\r\n",
        "#plt.show()\r\n",
        "#plt.figure(figsize = [10,8])\r\n",
        "#[plt.hist((cl_samples5[:,i].numpy()), bins = 'auto') for i in range(lmax-2)] #Histogram of the sampled cls for each l value.\r\n",
        "plt.legend((r'$\\ell$ = 0','$\\ell$ = 1','$\\ell$ = 2','$\\ell$ = 3','$\\ell$ = 4','$\\ell$ = 5'))\r\n",
        "plt.grid()\r\n",
        "plt.xlabel('Data:')\r\n",
        "plt.ylabel('Number of Instances:')\r\n",
        "plt.title('The sampling incidents of the HMC for each cl:')\r\n",
        "plt.show()\r\n",
        "\r\n",
        "lncl_samples6 = tf.slice(samples6,[0,0],[len(samples6),lmax-2]) #The sampled cls from the adaptive step size HMC\r\n",
        "cl_samples6 = tf.math.exp(lncl_samples6)\r\n",
        "_zer6 = tf.constant(0, dtype = np.float64)\r\n",
        "mean_cl6 = [tf.math.reduce_mean(cl_samples6[:,i])  for i in range(lmax-2)] #The mean of the sampled cls from the adaptive step size HMC\r\n",
        "std_cl6 = [tf.math.reduce_std(cl_samples6[:,i])  for i in range(lmax-2)] #The standard deviation of the = sampled cls from the adaptive step size HMC\r\n",
        "mean_cl6.insert(0,_zer6), mean_cl6.insert(0,_zer6)\r\n",
        "std_cl6.insert(0, _zer6), std_cl6.insert(0,_zer6)\r\n",
        "#plt.figure()\r\n",
        "#plotpwrspctrm(mean_cl6) # Plot of the mean sampled cls\r\n",
        "#plotpwrspctrm(orig_cls) #Plot of the original cls\r\n",
        "ell = np.arange(lmax)\r\n",
        "#plt.errorbar(ell,(ell*(ell+1)*mean_cl6),xerr = 0, yerr = (ell*(ell+1)*std_cl6))\r\n",
        "plt.grid()\r\n",
        "plt.legend(('final cls','inital cls'))\r\n",
        "#plt.show()\r\n",
        "#plt.figure(figsize = [10,8])\r\n",
        "#[plt.hist((cl_samples6[:,i].numpy()), bins = 'auto') for i in range(lmax-2)] #Histogram of the sampled cls for each l value.\r\n",
        "plt.legend((r'$\\ell$ = 0','$\\ell$ = 1','$\\ell$ = 2','$\\ell$ = 3','$\\ell$ = 4','$\\ell$ = 5'))\r\n",
        "plt.grid()\r\n",
        "plt.xlabel('Data:')\r\n",
        "plt.ylabel('Number of Instances:')\r\n",
        "plt.title('The sampling incidents of the HMC for each cl:')\r\n",
        "plt.show()\r\n",
        "'''\r\n",
        "'''\r\n",
        "lncl_samples7 = tf.slice(samples7,[0,0],[len(samples7),lmax-2]) #The sampled cls from the adaptive step size HMC\r\n",
        "cl_samples7 = tf.math.exp(lncl_samples7)\r\n",
        "_zer7 = tf.constant(0, dtype = np.float64)\r\n",
        "mean_cl7 = [tf.math.reduce_mean(cl_samples7[:,i])  for i in range(lmax-2)] #The mean of the sampled cls from the adaptive step size HMC\r\n",
        "std_cl7 = [tf.math.reduce_std(cl_samples7[:,i])  for i in range(lmax-2)] #The standard deviation of the = sampled cls from the adaptive step size HMC\r\n",
        "mean_cl7.insert(0,_zer7), mean_cl7.insert(0,_zer7)\r\n",
        "std_cl7.insert(0, _zer7), std_cl7.insert(0,_zer7)\r\n",
        "#plt.figure()\r\n",
        "#plotpwrspctrm(mean_cl7) # Plot of the mean sampled cls\r\n",
        "#plotpwrspctrm(orig_cls) #Plot of the original cls\r\n",
        "ell = np.arange(lmax)\r\n",
        "#plt.errorbar(ell,(ell*(ell+1)*mean_cl7),xerr = 0, yerr = (ell*(ell+1)*std_cl7))\r\n",
        "plt.grid()\r\n",
        "plt.legend(('final cls','inital cls'))\r\n",
        "#plt.show()\r\n",
        "#plt.figure(figsize = [10,8])\r\n",
        "#[plt.hist((cl_samples7[:,i].numpy()), bins = 'auto') for i in range(lmax-2)] #Histogram of the sampled cls for each l value.\r\n",
        "plt.legend((r'$\\ell$ = 0','$\\ell$ = 1','$\\ell$ = 2','$\\ell$ = 3','$\\ell$ = 4','$\\ell$ = 5'))\r\n",
        "plt.grid()\r\n",
        "plt.xlabel('Data:')\r\n",
        "plt.ylabel('Number of Instances:')\r\n",
        "plt.title('The sampling incidents of the HMC for each cl:')\r\n",
        "plt.show()\r\n",
        "'''\r\n",
        "'''\r\n",
        "lncl_samples8 = tf.slice(samples8,[0,0],[len(samples8),lmax-2]) #The sampled cls from the adaptive step size HMC\r\n",
        "cl_samples8 = tf.math.exp(lncl_samples8)\r\n",
        "_zer8 = tf.constant(0, dtype = np.float64)\r\n",
        "mean_cl8 = [tf.math.reduce_mean(cl_samples8[:,i])  for i in range(lmax-2)] #The mean of the sampled cls from the adaptive step size HMC\r\n",
        "std_cl8 = [tf.math.reduce_std(cl_samples8[:,i])  for i in range(lmax-2)] #The standard deviation of the = sampled cls from the adaptive step size HMC\r\n",
        "mean_cl8.insert(0,_zer8), mean_cl8.insert(0,_zer8)\r\n",
        "std_cl8.insert(0, _zer8), std_cl8.insert(0,_zer8)\r\n",
        "#plt.figure()\r\n",
        "#plotpwrspctrm(mean_cl8) # Plot of the mean sampled cls\r\n",
        "#plotpwrspctrm(orig_cls) #Plot of the original cls\r\n",
        "ell = np.arange(lmax)\r\n",
        "#plt.errorbar(ell,(ell*(ell+1)*mean_cl8),xerr = 0, yerr = (ell*(ell+1)*std_cl8))\r\n",
        "plt.grid()\r\n",
        "plt.legend(('final cls','inital cls'))\r\n",
        "#plt.show()\r\n",
        "#plt.figure(figsize = [10,8])\r\n",
        "#[plt.hist((cl_samples8[:,i].numpy()), bins = 'auto') for i in range(lmax-2)] #Histogram of the sampled cls for each l value.\r\n",
        "plt.legend((r'$\\ell$ = 0','$\\ell$ = 1','$\\ell$ = 2','$\\ell$ = 3','$\\ell$ = 4','$\\ell$ = 5'))\r\n",
        "plt.grid()\r\n",
        "plt.xlabel('Data:')\r\n",
        "plt.ylabel('Number of Instances:')\r\n",
        "plt.title('The sampling incidents of the HMC for each cl:')\r\n",
        "plt.show()\r\n",
        "'''\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yle4yqtvz793"
      },
      "source": [
        "#mean_clnp1 = []\r\n",
        "mean_clnp2 = []\r\n",
        "#mean_clnp3 = []\r\n",
        "#mean_clnp4 = []\r\n",
        "#mean_clnp5 = []\r\n",
        "#mean_clnp6 = []\r\n",
        "#mean_clnp7 = []\r\n",
        "#mean_clnp8 = []\r\n",
        "#std_clnp1 = []\r\n",
        "std_clnp2 = []\r\n",
        "#std_clnp3 = []\r\n",
        "#std_clnp4 = []\r\n",
        "#std_clnp5 = []\r\n",
        "#std_clnp6 = []\r\n",
        "#std_clnp7 = []\r\n",
        "#std_clnp8 = []\r\n",
        "for i in range(len(mean_cl2)):\r\n",
        "    #mean_clnp1.append(mean_cl1[i].numpy())\r\n",
        "    mean_clnp2.append(mean_cl2[i].numpy())\r\n",
        "    #mean_clnp3.append(mean_cl3[i].numpy())\r\n",
        "    #mean_clnp4.append(mean_cl4[i].numpy())\r\n",
        "    #mean_clnp5.append(mean_cl5[i].numpy())\r\n",
        "    #mean_clnp6.append(mean_cl6[i].numpy())\r\n",
        "    #mean_clnp7.append(mean_cl7[i].numpy())\r\n",
        "    #mean_clnp8.append(mean_cl8[i].numpy())\r\n",
        "    #std_clnp1.append(std_clnp1)\r\n",
        "    std_clnp2.append(std_clnp2)\r\n",
        "    #std_clnp3.append(std_clnp3)\r\n",
        "    #std_clnp4.append(std_clnp4)\r\n",
        "    #std_clnp5.append(std_clnp5)\r\n",
        "    #std_clnp6.append(std_clnp6)\r\n",
        "    #std_clnp7.append(std_clnp7)\r\n",
        "    #std_clnp8.append(std_clnp8)\r\n",
        "#mean_clnp1 = np.array(mean_clnp1)\r\n",
        "mean_clnp2 = np.array(mean_clnp2)\r\n",
        "#mean_clnp3 = np.array(mean_clnp3)\r\n",
        "#mean_clnp4 = np.array(mean_clnp4)\r\n",
        "#mean_clnp5 = np.array(mean_clnp5)\r\n",
        "#mean_clnp6 = np.array(mean_clnp6)\r\n",
        "#mean_clnp7 = np.array(mean_clnp7)\r\n",
        "#mean_clnp8 = np.array(mean_clnp8)\r\n",
        "#std_clnp1 = np.array(std_clnp1)\r\n",
        "std_clnp2 = np.array(std_clnp2)\r\n",
        "#std_clnp3 = np.array(std_clnp3)\r\n",
        "#std_clnp4 = np.array(std_clnp4)\r\n",
        "#std_clnp5 = np.array(std_clnp5)\r\n",
        "#std_clnp6 = np.array(std_clnp6)\r\n",
        "#std_clnp7 = np.array(std_clnp7)\r\n",
        "#std_clnp8 = np.array(std_clnp8)\r\n",
        "mean_cl_chain = (1/4)*(mean_clnp2)# + mean_clnp5 + mean_clnp6 + mean_clnp8) #The mean of the sampled cls from the adaptive step size HMC\r\n",
        "std_cl_chain = (std_clnp2**2)**0.5# + std_clnp5**2 + std_clnp6**2 + std_clnp8**2)**0.5  #The standard deviation of the = sampled cls from the adaptive step size HMC\r\n",
        "plt.figure()\r\n",
        "plotpwrspctrm(mean_cl_chain) # Plot of the mean sampled cls\r\n",
        "plotpwrspctrm(orig_cls) #Plot of the original cls\r\n",
        "ell = np.arange(lmax)\r\n",
        "plt.errorbar(ell,(ell*(ell+1)*mean_cl_chain),xerr = 0, yerr = (ell*(ell+1)*std_cl_chain))\r\n",
        "plt.grid()\r\n",
        "plt.legend(('final cls','inital cls'))\r\n",
        "plt.show()\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AwRsUSo7z8st"
      },
      "source": [
        "samplesnp = samples.numpy()\r\n",
        "rhattest = []\r\n",
        "for i in range(len(samplesnp-1)):\r\n",
        "    rhattest.append([])\r\n",
        "    rhattest[i].append(samples[i])\r\n",
        "rhattest_tf = tf.convert_to_tensor(rhattest)\r\n",
        "print(rhattest_tf)\r\n",
        "rhat = tfp.mcmc.diagnostic.potential_scale_reduction(rhattest_tf)\r\n",
        "print(rhat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFzzZ7S_z-zo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}